ai_small_bash:
	kubectl -n ai-models exec -ti ollama-small-599485c766-6rtsx -- /bin/bash

pull_o_image:
	ollama pull llama3.2

run_o_image:
	ollama run llama3.2